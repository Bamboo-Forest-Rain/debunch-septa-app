{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in function\n",
    "dtypes = {\n",
    "  'DoW': 'category',\n",
    "  'serviceDate': 'str',\n",
    "  'routeId': 'category',\n",
    "  'directionId': 'category',\n",
    "  'blockId': 'int16',\n",
    "  'tripId': 'int32',\n",
    "  'scheduledTripStartTime': 'str',\n",
    "  'scheduledRuntimeSeconds': 'int16',\n",
    "  'scheduledFromStopDepartureTime': 'str',\n",
    "  'observedRuntimeSeconds': 'float32',\n",
    "  'stopPathLength': 'float32',\n",
    "  'fromStopfrom_stop_stopPathIndex': 'int16',\n",
    "  'fromStopfrom_stop_name': 'category',\n",
    "  'fromStopfrom_stop_id': 'category',\n",
    "  'fromStopfrom_stop_gtfsStopSequence':'int16',\n",
    "  'fromStopfrom_stop_isScheduleAdherenceStop': 'bool',\n",
    "  'fromStopfrom_stop_isFirstStopInTrip': 'bool',\n",
    "  'fromStopfrom_stop_isLastStopInTrip': 'bool',\n",
    "  'fromStopfrom_stop_isWaitStop': 'bool',\n",
    "  'toStopto_stop_stopPathIndex': 'int16',\n",
    "  'toStopto_stop_name': 'category',\n",
    "  'toStopto_stop_id': 'category',\n",
    "  'toStopto_stop_gtfsStopSequence': 'int16',\n",
    "  'toStopto_stop_isScheduleAdherenceStop': 'bool',\n",
    "  'toStopto_stop_isFirstStopInTrip': 'bool',\n",
    "  'toStopto_stop_isLastStopInTrip': 'bool',\n",
    "  'toStopto_stop_isWaitStop': 'bool',\n",
    "  'speed_mph': 'float32'\n",
    "}\n",
    "columnsToRename = {\n",
    "  'fromStopfrom_stop_stopPathIndex': 'fromStopPathIndex',\n",
    "  'fromStopfrom_stop_name': 'fromStopName',\n",
    "  'fromStopfrom_stop_id': 'fromStopId',\n",
    "  'fromStopfrom_stop_gtfsStopSequence': 'fromStopSequence',\n",
    "  'fromStopfrom_stop_isScheduleAdherenceStop': 'fromStopIsScheduledAdherenceStop',\n",
    "  'fromStopfrom_stop_isFirstStopInTrip': 'fromStopIsTripFirstStop',\n",
    "  'fromStopfrom_stop_isLastStopInTrip': 'fromStopIsTripLastStop',\n",
    "  'fromStopfrom_stop_isWaitStop': 'fromStopIsWaitStop',\n",
    "  'toStopto_stop_stopPathIndex': 'toStopPathIndex',\n",
    "  'toStopto_stop_name': 'toStopName',\n",
    "  'toStopto_stop_id': 'toStopId',\n",
    "  'toStopto_stop_gtfsStopSequence': 'toStopSequence',\n",
    "  'toStopto_stop_isScheduleAdherenceStop': 'toStopIsScheduledAdherenceStop',\n",
    "  'toStopto_stop_isFirstStopInTrip': 'toStopIsTripFirstStop',\n",
    "  'toStopto_stop_isLastStopInTrip': 'toStopIsTripLastStop',\n",
    "  'toStopto_stop_isWaitStop': 'toStopIsWaitStop',\n",
    "}\n",
    "\n",
    "def readRuntimeData (path):\n",
    "  result = pd.read_csv(\n",
    "    path,\n",
    "    dtype=dtypes,\n",
    "    usecols=list(dtypes.keys())\n",
    "  ).rename(\n",
    "    columns=columnsToRename\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct and cast datetime\n",
    "def castDatetime (dateColumn, timeColumn):\n",
    "  hours = timeColumn.str.slice(0, 2).astype(int)\n",
    "  correctedHours = (hours % 24).astype(str).str.zfill(2)\n",
    "  timesExcludingHours = timeColumn.str.slice(start=2)\n",
    "  correctedTimes = correctedHours + timesExcludingHours\n",
    "\n",
    "  hourOverflowMask = hours >= 24\n",
    "\n",
    "  datetimeColumn = pd.to_datetime(\n",
    "    dateColumn +\n",
    "    ' ' +\n",
    "    correctedTimes\n",
    "  )\n",
    "  datetimeColumn[hourOverflowMask] = (\n",
    "    datetimeColumn[hourOverflowMask] +\n",
    "    pd.to_timedelta(1, unit='d')\n",
    "  )\n",
    "  return datetimeColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToCast = [\n",
    "  'scheduledTripStartTime', \n",
    "  'scheduledFromStopDepartureTime',\n",
    "]\n",
    "\n",
    "def castDatetimeColumns (runtimeDf):\n",
    "  # Scheduled departure time from terminal and each stop\n",
    "  for column in columnsToCast:\n",
    "    runtimeDf[column] = castDatetime(\n",
    "      runtimeDf['serviceDate'], \n",
    "      runtimeDf[column]\n",
    "    )\n",
    "  runtimeDf['serviceDate'] = pd.to_datetime(runtimeDf['serviceDate'])\n",
    "  \n",
    "  return runtimeDf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cumulative distance\n",
    "tripGroupByColumns = [\n",
    "  'routeId',\n",
    "  'serviceDate',\n",
    "  'directionId',\n",
    "  'tripId',\n",
    "]\n",
    "\n",
    "def addCumDistance (runtimeDf):\n",
    "  runtimeDf = runtimeDf.sort_values(\n",
    "    tripGroupByColumns + [\"toStopSequence\"]\n",
    "  ).dropna()\n",
    "\n",
    "  runtimeDf['cumDistance'] = runtimeDf.groupby(\n",
    "    tripGroupByColumns\n",
    "  )['stopPathLength'].cumsum()\n",
    "\n",
    "  return runtimeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scheduled and observed arrival times\n",
    "def addArrivalTimes (runtimeDf):\n",
    "  # Scheduled arrival time by stop\n",
    "  runtimeDf['scheduledToStopArrivalTime'] = (\n",
    "    runtimeDf['scheduledFromStopDepartureTime'] +\n",
    "    pd.to_timedelta(\n",
    "      runtimeDf['scheduledRuntimeSeconds'], \n",
    "      unit = 's'\n",
    "    )\n",
    "  )\n",
    "\n",
    "  runtimeDf = runtimeDf.sort_values(\n",
    "    tripGroupByColumns + ['toStopSequence']\n",
    "  ).dropna()\n",
    "  \n",
    "  # Get the cumulative seconds from starting from the terminus\n",
    "  runtimeDf['observedCumRuntimeSeconds'] = runtimeDf.groupby(\n",
    "    tripGroupByColumns\n",
    "  )['observedRuntimeSeconds'].cumsum().astype('int32')\n",
    "\n",
    "  runtimeDf['observedToStopArrivalTime'] = (\n",
    "    runtimeDf['scheduledTripStartTime'] +\n",
    "    pd.to_timedelta(\n",
    "      runtimeDf['observedCumRuntimeSeconds'],\n",
    "      unit = 's'\n",
    "    )\n",
    "  )\n",
    "  return runtimeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndProcessData (path):\n",
    "  runtimeDf = readRuntimeData(\n",
    "    path=path\n",
    "  )\n",
    "  runtimeDf = castDatetimeColumns(runtimeDf)\n",
    "  runtimeDf = addCumDistance(runtimeDf)\n",
    "  runtimeDf = addArrivalTimes(runtimeDf)\n",
    "\n",
    "  return runtimeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxPath = \"C:/Users/leeje/Box/Practicum_Otis_Bus/raw-data\"\n",
    "runtime = readAndProcessData(f\"{boxPath}/oct_16_31_weekday_runtimes.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate speed, lateness, and headway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "runtime = runtime.rename(columns={\n",
    "  \"speed_mph\": \"speed\"\n",
    "})\n",
    "\n",
    "# Add unique identifier to each arrival and use that as index\n",
    "numInstances = len(runtime)\n",
    "runtime['instanceId'] = range(numInstances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate: lateness compared to if average/uniform speed\n",
    "\n",
    "\"\"\"\n",
    "Find the expected average speed for each trip (regardless of service date)\n",
    "\"\"\"\n",
    "\n",
    "# Expected average speed is calculated by total trip distance divided by total trip time\n",
    "cumDistTime = runtime.query(\"toStopIsTripLastStop==True\").copy().groupby([\n",
    "  \"routeId\",\n",
    "  \"directionId\",\n",
    "  \"tripId\"\n",
    "])[[\n",
    "  \"observedCumRuntimeSeconds\",\n",
    "  \"cumDistance\"\n",
    "]].mean().dropna().reset_index()\n",
    "\n",
    "cumDistTime[\"expectedSpeed\"] = cumDistTime[\"cumDistance\"] / cumDistTime[\"observedCumRuntimeSeconds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge expected trip average speed to runtime DF\n",
    "# set_index again: prevent merge from disrupting index\n",
    "runtime = runtime.merge(\n",
    "  cumDistTime[[\n",
    "    \"routeId\", \"directionId\", \n",
    "    \"tripId\", \"expectedSpeed\"\n",
    "  ]],\n",
    "  how=\"left\",\n",
    "  left_on=[\"routeId\", \"directionId\", \"tripId\"],\n",
    "  right_on=[\"routeId\", \"directionId\", \"tripId\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected runtime seconds assuming using trip average speed as uniform speed\n",
    "runtime[\"expectedCumRuntimeSeconds\"] = runtime[\"cumDistance\"] / runtime[\"expectedSpeed\"]\n",
    "runtime = runtime.dropna()\n",
    "\n",
    "# Difference between runtime seconds compared to that assuming uniform speed\n",
    "runtime[\"late\"] = (\n",
    "  runtime[\"observedCumRuntimeSeconds\"] - runtime[\"expectedCumRuntimeSeconds\"]\n",
    ").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameServiceStopCols = [\"routeId\", \"directionId\", \"serviceDate\", \"toStopId\"]\n",
    "\n",
    "# Add instance of previous trip\n",
    "runtime = runtime.sort_values(\n",
    "    sameServiceStopCols + [\"scheduledToStopArrivalTime\"]\n",
    ")\n",
    "\n",
    "runtime[\"prevInstanceId\"] = runtime.groupby(\n",
    "    sameServiceStopCols\n",
    ")[\"instanceId\"].shift(1).astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameTripCols = [\"routeId\", \"directionId\", \"serviceDate\", \"tripId\"]\n",
    "\n",
    "runtime = runtime.sort_values(\n",
    "    sameTripCols + [\"toStopSequence\"]\n",
    ")\n",
    "\n",
    "runtime[\"lagInstanceId\"] = runtime.groupby(\n",
    "    sameTripCols\n",
    ")[\"instanceId\"].shift(1).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs\n",
    "\n",
    "runtime = runtime.dropna(subset=[\"prevInstanceId\", \"lagInstanceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toJoinFrom = runtime.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "toJoin = toJoinFrom[[\"instanceId\", \"observedToStopArrivalTime\", \"scheduledTripStartTime\"]].rename(\n",
    "    columns={\n",
    "      \"instanceId\": \"prevInstanceId\",\n",
    "      \"observedToStopArrivalTime\": \"prevBusArrivalTime\",\n",
    "      \"scheduledTripStartTime\": \"prevBusTripStartTime\"\n",
    "    }\n",
    ").dropna(subset=[\"prevInstanceId\"])\n",
    "\n",
    "runtimeDf = runtime.merge(\n",
    "    toJoin,\n",
    "    how=\"left\",\n",
    "    on=\"prevInstanceId\"\n",
    ").dropna(subset=[\"prevInstanceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed headway\n",
    "\n",
    "# Do a subtraction to get headway\n",
    "runtimeDf[\"headway\"] = ((\n",
    "  runtimeDf[\"observedToStopArrivalTime\"] - runtimeDf[\"prevBusArrivalTime\"]\n",
    ") / np.timedelta64(1, 's'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected headway\n",
    "\n",
    "# Do a subtraction to get headway\n",
    "runtimeDf[\"expectedHeadway\"] = ((\n",
    "  runtimeDf[\"scheduledTripStartTime\"] - runtimeDf[\"prevBusTripStartTime\"]\n",
    ") / np.timedelta64(1, 's'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "toJoinFrom = runtimeDf.copy().dropna(subset=[\"instanceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag headway\n",
    "\n",
    "toJoin = toJoinFrom[[\"instanceId\", \"headway\", \"speed\", \"late\"]].rename(\n",
    "    columns={\n",
    "        \"instanceId\": \"lagInstanceId\",\n",
    "        \"headway\": \"lagHeadway\",\n",
    "        \"speed\": \"lagSpeed\",\n",
    "        \"late\": \"lagLate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "runtimeDf = runtimeDf.merge(\n",
    "    toJoin,\n",
    "    how=\"left\",\n",
    "    on=\"lagInstanceId\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf[\"initBunching\"] = False\n",
    "runtimeDf.loc[\n",
    "    (runtimeDf[\"lagBunched\"] == False) & (runtimeDf[\"bunched\"] == True), \n",
    "    \"initBunching\"\n",
    "] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\"headway\", \"speed\", \"late\"]:\n",
    "  runtimeDf[f\"{var}LagDiff\"] = runtimeDf[var] - runtimeDf[f\"lag{var.title()}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeDf = runtimeDf.applymap(lambda x: np.nan if x is pd.NA else x)\n",
    "toJoinFrom = runtimeDf.copy().dropna(subset=[\"instanceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag headway\n",
    "\n",
    "toJoin = toJoinFrom[[\n",
    "  \"instanceId\", \"headway\", \"speed\", \"late\", \n",
    "  \"headwayLagDiff\", \"speedLagDiff\", \"lateLagDiff\"\n",
    "]].rename(\n",
    "    columns={\n",
    "        \"instanceId\": \"prevInstanceId\",\n",
    "        \"headway\": \"prevBus_headway\",\n",
    "        \"speed\": \"prevBus_speed\",\n",
    "        \"late\": \"prevBus_late\",\n",
    "        \"headwayLagDiff\": \"prevBus_headwayLagDiff\",\n",
    "        \"speedLagDiff\": \"prevBus_speedLagDiff\",\n",
    "        \"lateLagDiff\": \"prevBus_lateLagDiff\"\n",
    "    }\n",
    ")\n",
    "\n",
    "runtimeDf = runtimeDf.merge(\n",
    "    toJoin,\n",
    "    how=\"left\",\n",
    "    on=\"prevInstanceId\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagPredictors = [\"speed\", \"headway\", \"late\"]\n",
    "lagDiffPredictors = [f\"{var}LagDiff\" for var in [\"speed\", \"headway\", \"late\"]]\n",
    "lagPredictors = lagPredictors + lagDiffPredictors\n",
    "preBusPredictors = [f\"prevBus_{var}\" for var in lagPredictors]\n",
    "\n",
    "allLagPredictors = lagPredictors + preBusPredictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = [\"21\", \"47\", \"33\"]\n",
    "desired_date = \"2022-10-26\"\n",
    "desired_time = \"2022-10-26 08:30:16\"\n",
    "\n",
    "query = \"(routeId.isin(@routes)) & (serviceDate == @desired_date)\"\n",
    "runtime_sel = runtimeDf.query(query).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the trips on this day with their time range\n",
    "trips = runtime_sel.groupby(\"tripId\")[\"observedToStopArrivalTime\"].agg([\"min\", \"max\"])\n",
    "trips_sel = trips.query(\"min < @desired_time < max\").copy()\n",
    "tripIds_sel = trips_sel.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_used = runtime_sel.query(\"tripId in @tripIds_sel\").copy()\n",
    "# Time range of each arrival instance\n",
    "runtime_used[\"observedFromStopDepartureTime\"] = runtime_used[\n",
    "    \"observedToStopArrivalTime\"\n",
    "] - pd.to_timedelta(runtime_used[\"observedRuntimeSeconds\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_used = runtime_used.query(\n",
    "    \"observedFromStopDepartureTime < @desired_time < observedToStopArrivalTime\"\n",
    ").copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce realtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "stops = gpd.read_file(\"../../db/stops-all.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Generate fake transit view data (locations)\n",
    "# ==============================================================================\n",
    "\n",
    "realtime = runtime_used[\n",
    "    [\"routeId\", \"directionId\", \"tripId\", \"toStopId\", \"toStopName\", \"toStopSequence\"]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"toStopId\": \"next_stop_id\",\n",
    "        \"toStopName\": \"next_stop_name\",\n",
    "        \"toStopSequence\": \"next_stop_sequence\",\n",
    "        \"routeId\": \"route_id\",\n",
    "        \"tripId\": \"trip\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_dict = {\n",
    "    21: {0: \"Eastbound\", 1: \"Westbound\"},\n",
    "    33: {0: \"Southbound\", 1: \"Northbound\"},\n",
    "    47: {0: \"Southbound\", 1: \"Northbound\"},\n",
    "}\n",
    "realtime[\"Direction\"] = realtime.apply(\n",
    "    lambda row: direction_dict[int(row.route_id)][int(row.directionId)], axis=1\n",
    ")\n",
    "realtime = realtime.drop(\"directionId\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.StopId = stops.StopId.astype(str)\n",
    "\n",
    "stops = (\n",
    "    stops[[\"StopId\", \"Lon\", \"Lat\"]]\n",
    "    .rename(columns={\"StopId\": \"next_stop_id\", \"Lon\": \"lng\", \"Lat\": \"lat\"})\n",
    "    .drop_duplicates(subset=[\"next_stop_id\"])\n",
    ")\n",
    "\n",
    "realtime = realtime.merge(stops, how=\"left\", on=\"next_stop_id\")\n",
    "\n",
    "for route in routes:\n",
    "    subset = realtime.query(\"route_id == @route\").copy()\n",
    "    json_data = {\"bus\": subset.to_dict(orient=\"records\")}\n",
    "\n",
    "    with open(f\"../../db/demo-transit-view/{route}.json\", \"w\") as f:\n",
    "        json.dump(json_data, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_used[\"period\"] = runtime_used.scheduledTripStartTime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBasePredictors = [\"toStopPathIndex\"]\n",
    "catPredictors = [\"directionId\", \"period\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(\"../serialized-models/21-11.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for route in [\"47\", \"21\", \"33\"]:\n",
    "  globals()[f\"subset_{route}\"] = runtime_used.query(\"routeId == @route\").copy()\n",
    "  for steps in range(11, 21):\n",
    "    model = load(f\"../serialized-models/{route}-{steps}.joblib\")\n",
    "    probs = model.predict_proba(\n",
    "       globals()[f\"subset_{route}\"]\n",
    "    )[:,1]\n",
    "    globals()[f\"subset_{route}\"][f\"pred_{steps}\"] = probs > 0.012\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.concat(\n",
    "    [subset_21, subset_33, subset_47], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in prediction.iterrows():\n",
    "  data = row[1]\n",
    "  route = data[\"routeId\"]\n",
    "  direction = data[\"directionId\"]\n",
    "  trip = data[\"tripId\"]\n",
    "  predictions = [data[f\"pred_{steps}\"] for steps in range(11, 21)]\n",
    "  json_data = {\n",
    "    \"prediction\": predictions\n",
    "  }\n",
    "  with open(f\"../../db/demo-prediction-forward/{route}-{direction}-{trip}.json\", \"w\") as f:\n",
    "    json.dump(json_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-550-fall-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
